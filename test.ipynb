{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import sklearn.metrics\n",
    "from typing import Dict, List, Optional\n",
    "import albumentations as A\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import rasterio\n",
    "import ttach as tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cfg:\n",
    "    model_name             = \"maxvit_tiny_tf_512.in1k\" # tf_efficientnet_b0, convnext_atto, convnextv2_nano.fcmae_ft_in22k_in1k_384\n",
    "    img_size               = 512  # 128, 512\n",
    "    num_classes            = 1\n",
    "    in_channels            = 1    # 1, 13\n",
    "    batch_size             = 8\n",
    "    drop_rate              = 0.0\n",
    "    drop_path_rate         = 0.0\n",
    "    iters_to_accumulate    = 1\n",
    "    grad_clip              = None # None\n",
    "\n",
    "    device                 = \"cuda\"\n",
    "    use_amp                = False   #? bfloat?16\n",
    "    compile                = False\n",
    "    num_workers            = 4\n",
    "    exp_name               = \"exp1\" \n",
    "    seed                   = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetDataset(Dataset):\n",
    "    def __init__(self, df, cfg, transform):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.df = df # np.array\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.val_transforms = A.Compose(\n",
    "            [   \n",
    "                # A.Resize(cfg.img_size, cfg.img_size),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        row = self.df.iloc[i]\n",
    "        with rasterio.open(\"test_images/\" + row.filename) as img:\n",
    "            x = img.read().astype(np.float32)  #[1:4] [[1,2,3,4]]\n",
    "\n",
    "        x = np.concatenate((x, x[1:4]))\n",
    "        img_rows = []\n",
    "        for min_id in range(0, 16, 4):\n",
    "            img_row = np.hstack([i for i in x[min_id:min_id+4]])\n",
    "            img_rows.append(img_row) #.transpose(2, 1, 0)\n",
    "        x = np.vstack(img_rows)\n",
    "\n",
    "        x = np.where(x < 0, 0, x)\n",
    "        max, min = 2.8003, 0.0\n",
    "        x = (x - min) / (max - min + 1e-8)\n",
    "\n",
    "        # x = x.transpose(1,2,0)\n",
    "        transformed = self.val_transforms(image=x)\n",
    "        x = transformed[\"image\"]\n",
    "        # x = x.transpose(1,0) \n",
    "        # x = torch.unsqueeze(x, dim=0)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.model = timm.create_model(self.cfg.model_name, pretrained=True, num_classes=self.cfg.num_classes, \n",
    "                                       in_chans=self.cfg.in_channels, drop_rate=self.cfg.drop_rate, \n",
    "                                       drop_path_rate=self.cfg.drop_path_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Datasetloader(df, cfg):\n",
    "    validloader = None\n",
    "        \n",
    "    valid_dataset = NetDataset(df, cfg, \"val\")\n",
    "    validloader = DataLoader(valid_dataset, batch_size=cfg.batch_size, shuffle=False, \n",
    "                             num_workers=cfg.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    return validloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, validloader, cfg):\n",
    "    preds = []\n",
    "\n",
    "    transforms = tta.Compose(\n",
    "        [\n",
    "            # tta.HorizontalFlip(),\n",
    "            # tta.VerticalFlip(),\n",
    "            # tta.Rotate90(angles=[0, 180]),\n",
    "            # tta.Scale(scales=[1, 2, 4]),\n",
    "            # tta.Multiply(factors=[0.9, 1, 1.1]),        \n",
    "        ]\n",
    "    )\n",
    "    model = tta.ClassificationTTAWrapper(model, transforms)\n",
    "\n",
    "    model.eval()\n",
    "    for (x) in tqdm(validloader): #tqdm\n",
    "        x = x.to(cfg.device)\n",
    "        with torch.inference_mode():  \n",
    "            with torch.autocast(device_type=cfg.device, dtype=torch.float16, enabled=cfg.use_amp):\n",
    "                logits = model(x)#.squeeze()\n",
    "\n",
    "        preds.append(logits.detach().cpu())\n",
    "\n",
    "    preds = torch.cat(preds)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:09<00:00, 18.92it/s]\n"
     ]
    }
   ],
   "source": [
    "cfg = Cfg()\n",
    "\n",
    "if cfg.use_amp == False:\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "\n",
    "df = pd.read_csv(\"sample_answer.csv\")\n",
    "\n",
    "validloader = Datasetloader(df, cfg)\n",
    "\n",
    "model_paths = [\n",
    "                # \"1_convnext_atto_3e4_L1_tta_fold0_epoch20.pt\", \n",
    "                #    \"convnext_atto_3e4_L1_tta_fold0_epoch20.pt\",\n",
    "                #    \"convnext_atto_40_3e4_L1_tta_fold0_epoch20.pt\",\n",
    "                # \"convnext_atto_3e4_MSE_tta_fold0_epoch20.pt\", # 0.9790\n",
    "                # \"convnext_atto_3e4_L1_bunchaaug_tta_fold0_epoch20.pt\", # 0.9855\n",
    "                # \"convnext_atto_3e4_L1_tta_4x4_fold0_epoch20.pt\", # 0.9828\n",
    "                # \"maxvit_tiny_tf_384.in1k_1e4_L1_tta_fold0_epoch20.pt\", # 0.9863\n",
    "                # \"convnext_atto_16b_1e4_L1_tta_fold0_epoch20.pt\", # 0.984\n",
    "                # \"maxvit_tiny_tf_512.in1k_4x4_3e4_L1_tta_bs8_fold0_epoch20.pt\", # 0.9896\n",
    "                # \"maxvit_tiny_tf_512.in1k_4x4_3e4_L1_tta_bs8_dr0.1_fold0_epoch20.pt\", # 0.9774\n",
    "                # \"maxvit_tiny_tf_512.in1k_4x4_1e4_L1_tta_bs8_dr01_fold0_epoch20.pt,   # 0.9884\n",
    "                # \"convnext_atto_4x4_3e4_L1_bs16_dr01_fold0_epoch20.pt\",\n",
    "                # \"convnext_atto_4x4_3e4_L1_tta_bs16_dr01_fold0_epoch40.pt\",\n",
    "                # \"maxvit_tiny_tf_384.in1k_3e4_L1_tta_bs8_384_fold0_epoch20.pt\",\n",
    "                 \"maxvit_tiny_tf_512.in1k_3e4_L1_tta_bs8_384_fold0_epoch20.pt\",\n",
    "               ]\n",
    "\n",
    "ensembled = None\n",
    "for i in range(len(model_paths)):\n",
    "    model = Net(cfg).to(cfg.device) \n",
    "    model.load_state_dict(torch.load(\"models/\" + model_paths[i]))\n",
    "    pred = eval_model(model, validloader, cfg)\n",
    "    if ensembled is None:\n",
    "        ensembled = pred\n",
    "    else:\n",
    "        ensembled += pred\n",
    "\n",
    "preds = ensembled / len(model_paths)\n",
    "\n",
    "df.target = preds\n",
    "df.to_csv(\"submission.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_1.tif</td>\n",
       "      <td>0.081642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_2.tif</td>\n",
       "      <td>0.199914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_3.tif</td>\n",
       "      <td>0.211495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_4.tif</td>\n",
       "      <td>0.110665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_5.tif</td>\n",
       "      <td>0.085977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>test_1485.tif</td>\n",
       "      <td>0.096455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>test_1486.tif</td>\n",
       "      <td>0.171889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>test_1487.tif</td>\n",
       "      <td>0.159528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>test_1488.tif</td>\n",
       "      <td>0.103038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>test_1489.tif</td>\n",
       "      <td>0.017432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1489 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename      pred\n",
       "0        test_1.tif  0.081642\n",
       "1        test_2.tif  0.199914\n",
       "2        test_3.tif  0.211495\n",
       "3        test_4.tif  0.110665\n",
       "4        test_5.tif  0.085977\n",
       "...             ...       ...\n",
       "1484  test_1485.tif  0.096455\n",
       "1485  test_1486.tif  0.171889\n",
       "1486  test_1487.tif  0.159528\n",
       "1487  test_1488.tif  0.103038\n",
       "1488  test_1489.tif  0.017432\n",
       "\n",
       "[1489 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs = [\"submissions/maxvit_0.9896_sub.csv\",\n",
    "        \"submissions/0.9884_maxvit.csv\",\n",
    "        # \"submissions/sub_convnext_atto_4x4_3e4_L1_bs16_dr01_fold0_epoch20.csv\",\n",
    "        # \"submissions/sub_convnext_atto_4x4_3e4_L1_bs16_dr01_fold0_epoch40.csv\",\n",
    "        # \"submissions/sub_maxvit_tiny_tf_384.in1k_3e4_L1_tta_bs8_384_fold0_epoch20.csv\",\n",
    "        \"submissions/sub_maxvit_tiny_tf_512.in1k_3e4_L1_tta_bs8_384_fold0_epoch20.csv\",\n",
    "        ]\n",
    "\n",
    "ensembled = None\n",
    "for i in range(len(subs)):\n",
    "    if ensembled is None:\n",
    "        ensembled = pd.read_csv(subs[i]).pred\n",
    "    else:\n",
    "        ensembled += pd.read_csv(subs[i]).pred\n",
    "\n",
    "ensembled = ensembled / len(subs)\n",
    "ensembled = pd.concat([df.filename, ensembled], axis=1)\n",
    "ensembled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembled.to_csv(\"ensemble_sub.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
